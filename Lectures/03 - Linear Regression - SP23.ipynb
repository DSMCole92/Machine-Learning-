{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Supervised Learning and Loss Functions\n",
    "\n",
    "The goal in a supervised learning task is to produce a **model** that we can use to predict the value of a label (or response) $y$ given values for a set of features (or predictors), $x^{(1)}, x^{(2)}, ..., x^{(p)}$. This model is typically represented by a **`predict()`** function. \n",
    "\n",
    "When we select a learning algorithm, we are effectively selecting a class of models that we will be considering for our particular task. This set of allowed models is called our **hypothesis space**. Our learning algorithm will search through the hypothesis space to find the model that performs the best on our training data. To determine what model from the hypothesis space is the \"best\", we need to provide the learning algorithm with a method of score different models. Such a scoring method is called an **objective function**. An objective function takes a model and a dataset as input, and produces a numerical score as its output. If an objective function is defined in such a way that lower scores are better, then we call it a **loss** function. The goal of a learning algorithm is to minimize its loss on the training data. \n",
    "\n",
    "We will illustrate these concepts with the **linear regression learning algorithm**. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lesson 03 - Linear Regression\n",
    "\n",
    "### The following topics are discussed in this notebook:\n",
    "* Loss Functions.\n",
    "* Simple Linear Regression\n",
    "* Multiple Linear Regression\n",
    "* Linear Regression using scikit-learn.\n",
    "\n",
    "### Additional Resources\n",
    "* [Python Data Science Handbook, Ch 2] - intro to NumPy arrays \n",
    "* [Hands-On Machine Learning, Ch 4](https://github.com/ageron/handson-ml/blob/master/04_training_linear_models.ipynb)\n",
    "* [Introduction to Machine Learning, Ch 3](http://www-bcf.usc.edu/~gareth/ISL/ISLR%20Seventh%20Printing.pdf)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear Regresion\n",
    "\n",
    "*In a simple linear regression task, we have a single FEATURE, `x`, from which we wish to predict a continuous, real-valued LABEL `y`.\n",
    "\n",
    "* Assume that our training set has $n$ observations.\n",
    "* Denote the observed values of the training feature (predictor) as $x_1, x_2, ..., x_n$.\n",
    "* Denote the observed values of the label (response variable) as $y_1, y_2, ..., y_n$.\n",
    "* We assume that our model has the following form: $\\large \\hat{y} = \\hat{\\beta}_0 + \\hat{\\beta}_1 x$.\n",
    "* In the model above, $\\hat{\\beta}_0$ and $\\hat\\beta_1$ are model parameters that are learned from the training data. \n",
    "* $\\hat{y}$ represents the predicted value of $y$ given some value of $x$. \n",
    "\n",
    "### Training the Model\n",
    "\n",
    "* Let $b_0$ and $b_1$ be a pair of (not necessarily optimal) parameter values used to define a model $\\large \\hat{y} = {b}_0 + {b}_1 x$.\n",
    "* For each training observation $(x_i, y_i)$, let $\\large\\hat{y}_i = b_0 + b_1 x_i$. \n",
    "* For each $i$, calculate the error (residual) $\\large\\hat{e}_i = \\hat{y}_i - y_i$. \n",
    "* The goal of the algorithm is to find the parameter values that minimize the Sum of Squared Errors loss function, given by: $ \\large SSE = \\sum \\hat{e}_i^2 $\n",
    "* We will denote the optimal parameter values by $\\hat{\\beta}_0$ and $\\hat{\\beta}_1$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 2 3 4 5]\n",
      "(5,)\n",
      "[ 4.9  7.1  9.3 10.2 13.5]\n",
      "(5,)\n",
      "(5, 1)\n",
      "(5,)\n"
     ]
    }
   ],
   "source": [
    "# First, let's generate some data, define some model for the data, and compute (by hand) the SSE for it...\n",
    "import numpy as np\n",
    "x = np.array([1, 2, 3, 4,5 ])\n",
    "print(x)\n",
    "print(x.shape)\n",
    "y = np.array([4.9, 7.1, 9.3, 10.2, 13.5])\n",
    "print(y)\n",
    "print(y.shape)\n",
    "\n",
    "X = x.reshape(len(x),1)\n",
    "print(X.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEGCAYAAABo25JHAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8QVMy6AAAACXBIWXMAAAsTAAALEwEAmpwYAAAPr0lEQVR4nO3df6ieZ33H8ffHJOJprUTJUZu0kk4kIGUscuamBSetXbpZNIz9YUHXOSH/TK37kc7MYRmMbSzDOdhwhLbaYa1IjZnIZiz+oJNp15OmmtY0VlzVJHU5pcv8sbM1jd/9cZ7U5Jg054TzPNc5z/V+weGc537u9PrclJxP7uu+7+tJVSFJ6tdzWgeQJLVlEUhS5ywCSeqcRSBJnbMIJKlzq1sHWIh169bVxo0bW8eQpBVl3759T1TV5Pn2WxFFsHHjRqanp1vHkKQVJcl3FrKfU0OS1DmLQJI6ZxFIUucsAknqnEUgSZ2zCCSpcxaBJHXOIpCkzlkEktQ5i0CSOje0Ikhye5JjSR46y3t/mKSSrBvW+JKkhRnmGcFHgOvmb0xyOXAt8N0hji1JWqChFUFV3Qs8eZa3/ga4GfDDkiVpGRjpNYIkbwKOVNXXFrDvtiTTSaZnZmZGkE6S+jSyIkhyEfA+4P0L2b+qdlXVVFVNTU6edzltSdIFGuUZwcuBK4CvJXkMuAx4IMlLR5hBkjTPyD6YpqoOAC8+9XpQBlNV9cSoMkiSftbQiiDJXcDrgXVJDgO3VNVtwxpPkhZqz/4j7Nx7iKPHZ1m/doLtWzaxdfOG1rGaGVoRVNUN53l/47DGlqRz2bP/CDt2H2D2xEkAjhyfZcfuAwDdloFPFkvqys69h54pgVNmT5xk595DjRK1ZxFI6srR47OL2t4Di0BSV9avnVjU9h5YBJK6sn3LJibWrDpj28SaVWzfsqlRovZGdvuoJC0Hpy4Ie9fQT1kEkrqzdfOGrn/xz+fUkCR1ziKQpM5ZBJLUOYtAkjpnEUhS5ywCSeqcRSBJnbMIJKlzFoEkdc4ikKTOWQSS1DmLQJI6ZxFIUucsAknq3NCKIMntSY4leei0bTuTPJLk60k+lWTtsMaXJC3MMM8IPgJcN2/bPcCVVfXzwDeBHUMcX5K0AEMrgqq6F3hy3rbPVdXTg5dfBS4b1viSpIVpeY3gd4B/OdebSbYlmU4yPTMzM8JYktSXJkWQ5H3A08Cd59qnqnZV1VRVTU1OTo4unCR1ZuSfWZzkRuB64JqqqlGPL0k600iLIMl1wB8Bv1JV/zPKsSVJZzfM20fvAr4CbEpyOMk7gL8DLgHuSfJgkn8Y1viSpIUZ2hlBVd1wls23DWs8SdKF8cliSeqcRSBJnbMIJKlzFoEkdc4ikKTOWQSS1DmLQJI6ZxFIUucsAknqnEUgSZ2zCCSpcxaBJHXOIpCkzlkEktQ5i0CSOmcRSFLnLAJJ6tzIP7xe0vK3Z/8Rdu49xNHjs6xfO8H2LZvYunlD61gaEotA0hn27D/Cjt0HmD1xEoAjx2fZsfsAgGUwppwaknSGnXsPPVMCp8yeOMnOvYcaJdKwDa0Iktye5FiSh07b9qIk9yR5dPD9hcMaX9KFOXp8dlHbtfIN84zgI8B187a9F/h8Vb0C+PzgtaRlZP3aiUVt18o3tCKoqnuBJ+dtfjNwx+DnO4Ctwxpf0oXZvmUTE2tWnbFtYs0qtm/Z1CiRhm3UF4tfUlWPA1TV40lefK4dk2wDtgG87GUvG1E8SacuCHvXUD9SVcP7jycbgc9U1ZWD18erau1p7/9XVZ33OsHU1FRNT08PLackjaMk+6pq6nz7jfquof9McinA4PuxEY8vSZpn1EXwaeDGwc83Av804vElSfMM8/bRu4CvAJuSHE7yDuAvgWuTPApcO3gtSWpoaBeLq+qGc7x1zbDGlCQtnk8WS1LnXGtIugAuyqZxYhFIi+SibBo3Tg1Ji+SibBo3FoG0SC7KpnFjEUiL5KJsGjcWgbRILsqmcePFYmmRXJRN48YikC7A1s0b/MWvseHUkCR1ziKQpM5ZBJLUOYtAkjpnEUhS5ywCSeqcRSBJnbMIJKlzFoEkdc4ikKTOWQSS1LkmRZDk95I8nOShJHcleV6LHJKkBkWQZAPwbmCqqq4EVgFvGXUOSdKcVlNDq4GJJKuBi4CjjXJIUvdGXgRVdQT4a+C7wOPAf1fV5+bvl2Rbkukk0zMzM6OOKUndaDE19ELgzcAVwHrg4iRvnb9fVe2qqqmqmpqcnBx1TEnqRoupoTcA/1FVM1V1AtgNvLZBDkkSbYrgu8AvJ7koSYBrgIMNckiSaHON4D7gbuAB4MAgw65R55AkzWnymcVVdQtwS4uxJUlnOu8ZQZJ3Di7wSpLG0EKmhl4K3J/kE0muG8zrS5LGxHmLoKr+BHgFcBvw28CjSf48ycuHnE2SNAILulhcVQV8f/D1NPBC4O4kfzXEbJKkETjvxeIk7wZuBJ4AbgW2V9WJJM8BHgVuHm5ErVR79h9h595DHD0+y/q1E2zfsomtmze0jiVpnoXcNbQO+I2q+s7pG6vqJ0muH04srXR79h9hx+4DzJ44CcCR47Ps2H0AwDKQlpmFXCN4//wSOO09HwTTWe3ce+iZEjhl9sRJdu491CiRpHPxg2k0FEePzy5qu6R2LAINxfq1E4vaLqkdi0BDsX3LJibWrDpj28SaVWzfsqlRIknn0mSJCY2/UxeEvWtIWv4sAg3N1s0b/MUvrQBODUlS5ywCSeqcRSBJnbMIJKlzFoEkdc4ikKTOWQSS1DmLQJI616QIkqxNcneSR5IcTPKaFjkkSe2eLP5b4LNV9ZtJngtc1CiHJHVv5EWQ5AXA65j7/GOq6ingqVHnkCTNaTE19HPADPDhJPuT3Jrk4vk7JdmWZDrJ9MzMzOhTSlInWhTBauBVwIeqajPwY+C983eqql1VNVVVU5OTk6POKEndaFEEh4HDVXXf4PXdzBWDJKmBkRdBVX0f+F6SU59Qcg3wjVHnkCTNaXXX0LuAOwd3DH0beHujHJLUvSZFUFUPAlMtxpYknckniyWpcxaBJHXOIpCkzlkEktQ5i0CSOmcRSFLnLAJJ6lyrB8oE7Nl/hJ17D3H0+Czr106wfcsmtm7e0DqWpM5YBI3s2X+EHbsPMHviJABHjs+yY/cBAMtA0kg5NdTIzr2HnimBU2ZPnGTn3kONEknqlUXQyNHjs4vaLknDYhE0sn7txKK2S9KwWASNbN+yiYk1q87YNrFmFdu3bDrHn5Ck4fBicSOnLgh715Ck1iyChrZu3uAvfknNOTUkSZ2zCCSpcxaBJHXOIpCkzlkEktS5ZkWQZFWS/Uk+0yqDJKntGcFNwMGG40uSaFQESS4D3gjc2mJ8SdJPtToj+CBwM/CTc+2QZFuS6STTMzMzIwsmSb0ZeREkuR44VlX7nm2/qtpVVVNVNTU5OTmidJLUnxZnBFcBb0ryGPBx4OokH22QQ5JEgyKoqh1VdVlVbQTeAnyhqt466hySpDk+RyBJnWu6+mhVfQn4UssMktQ7zwgkqXMWgSR1ziKQpM5ZBJLUOYtAkjpnEUhS5ywCSeqcRSBJnbMIJKlzFoEkdc4ikKTOWQSS1DmLQJI6ZxFIUucsAknqnEUgSZ2zCCSpcxaBJHXOIpCkzlkEktS5kRdBksuTfDHJwSQPJ7lp1BkkST+1usGYTwN/UFUPJLkE2Jfknqr6RoMsktS9kZ8RVNXjVfXA4OcfAgeBDaPOIUma0/QaQZKNwGbgvrO8ty3JdJLpmZmZkWeTpF40K4Ikzwc+Cbynqn4w//2q2lVVU1U1NTk5OfqAktSJJkWQZA1zJXBnVe1ukUGSNKfFXUMBbgMOVtUHRj2+JOlMLc4IrgLeBlyd5MHB1683yCFJosHto1X1ZSCjHleSdHY+WSxJnbMIJKlzFoEkdc4ikKTOWQSS1DmLQJI6ZxFIUucsAknqnEUgSZ2zCCSpcxaBJHXOIpCkzlkEktQ5i0CSOmcRSFLnLAJJ6pxFIEmdswgkqXMWgSR1ziKQpM41KYIk1yU5lORbSd7bIoMkac7IiyDJKuDvgV8DXgnckOSVo84hSZrT4ozg1cC3qurbVfUU8HHgzQ1ySJKA1Q3G3AB877TXh4Ffmr9Tkm3AtsHL/0vy0AiytbIOeKJ1iCEa5+Mb52MDj2+l27SQnVoUQc6yrX5mQ9UuYBdAkumqmhp2sFY8vpVrnI8NPL6VLsn0QvZrMTV0GLj8tNeXAUcb5JAk0aYI7gdekeSKJM8F3gJ8ukEOSRINpoaq6ukk7wT2AquA26vq4fP8sV3DT9aUx7dyjfOxgce30i3o+FL1M9PzkqSO+GSxJHXOIpCkzi3rIhj3pSiS3J7k2Dg+I5Hk8iRfTHIwycNJbmqdaSkleV6Sf0/ytcHx/WnrTEstyaok+5N8pnWWYUjyWJIDSR5c6G2WK0WStUnuTvLI4O/ga551/+V6jWCwFMU3gWuZu+X0fuCGqvpG02BLKMnrgB8B/1hVV7bOs5SSXApcWlUPJLkE2AdsHZf/f0kCXFxVP0qyBvgycFNVfbVxtCWT5PeBKeAFVXV96zxLLcljwFRVjd0DZUnuAP61qm4d3J15UVUdP9f+y/mMYOyXoqiqe4EnW+cYhqp6vKoeGPz8Q+Agc0+Vj4Wa86PByzWDr+X5r6oLkOQy4I3Ara2zaHGSvAB4HXAbQFU99WwlAMu7CM62FMXY/CLpSZKNwGbgvsZRltRg6uRB4BhwT1WN0/F9ELgZ+EnjHMNUwOeS7BssaTMufg6YAT48mNq7NcnFz/YHlnMRLGgpCi1vSZ4PfBJ4T1X9oHWepVRVJ6vqF5h7Ov7VScZiei/J9cCxqtrXOsuQXVVVr2JuJeTfHUzVjoPVwKuAD1XVZuDHwLNeY13OReBSFCvcYO78k8CdVbW7dZ5hGZx2fwm4rm2SJXMV8KbBHPrHgauTfLRtpKVXVUcH348Bn2JuOnocHAYOn3aGejdzxXBOy7kIXIpiBRtcTL0NOFhVH2idZ6klmUyydvDzBPAG4JGmoZZIVe2oqsuqaiNzf+++UFVvbRxrSSW5eHATA4Npk18FxuLuvar6PvC9JKdWHr0GeNabNFqsProgF7gUxYqS5C7g9cC6JIeBW6rqtraplsxVwNuAA4N5dIA/rqp/bhdpSV0K3DG4u+05wCeqaixvsxxTLwE+NffvFVYDH6uqz7aNtKTeBdw5+Ef0t4G3P9vOy/b2UUnSaCznqSFJ0ghYBJLUOYtAkjpnEUhS5ywCSeqcRSBJnbMIJKlzFoF0AZL8YpKvDz6X4OLBZxKMxVpD6o8PlEkXKMmfAc8DJphb2+UvGkeSLohFIF2gweP79wP/C7y2qk42jiRdEKeGpAv3IuD5wCXMnRlIK5JnBNIFSvJp5pZpvoK5j+V8Z+NI0gVZtquPSstZkt8Cnq6qjw1WIP23JFdX1RdaZ5MWyzMCSeqc1wgkqXMWgSR1ziKQpM5ZBJLUOYtAkjpnEUhS5ywCSerc/wM54TvUP47wqQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#before computations - let's plot the data\n",
    "\n",
    "%matplotlib inline\n",
    "#To set this up, before any plotting or import of matplotlib is performed \n",
    "#you must execute the %matplotlib magic command. \n",
    "#This performs the necessary behind-the-scenes setup for IPython \n",
    "#to work correctly hand in hand with matplotlib; it does not, however, \n",
    "#actually execute any Python import commands, that is, no names are added to the namespace.\n",
    "import numpy as np\n",
    "from ipywidgets import *\n",
    "from IPython.display import display, HTML, Markdown\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "\n",
    "plt.close()\n",
    "plt.scatter(x,y)\n",
    "\n",
    "plt.xlim([0,6])\n",
    "plt.ylim([0,15])\n",
    "plt.xlabel('x')\n",
    "plt.ylabel('y')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#It looks like the points make a line with slope equal about m=2 and y-intercept about b=3\n",
    "#Let's plot   y=3+2x  wiht the data points...\n",
    "b = 3\n",
    "m = 2\n",
    "\n",
    "plt.close()\n",
    "plt.scatter(x,y)\n",
    "plt.plot([0,6],[m*0 + b, m*6 + b], c='g')\n",
    "plt.xlim([0,6])\n",
    "plt.ylim([0,15])\n",
    "plt.xlabel('x')\n",
    "plt.ylabel('y')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now spend some time computing  the SSE  and the score (called r_Squared)...    By hand!\n",
    "\n",
    "## Computing SSE\n",
    "* Let $b_0$ and $b_1$ be a pair of (not necessarily optimal) parameter values used to define a model $\\large \\hat{y} = {b}_0 + {b}_1 x$.\n",
    "* For each training observation $(x_i, y_i)$, let $\\large\\hat{y}_i = b_0 + b_1 x_i$. \n",
    "* For each $i$, calculate the error (residual) $\\large\\hat{e}_i = \\hat{y}_i - y_i$. \n",
    "* The goal of the algorithm is to find the parameter values that minimize the Sum of Squared Errors loss function, given by: $ \\large SSE = \\sum \\hat{e}_i^2 $\n",
    "\n",
    "## Computing r-Squared\n",
    "\n",
    "When working with linear regression, the optimal parameter values are determined by minimizing the objective function SSE. However, a different value is typically used to assess the quality of a regression model. This alternate scoring method is called the called the **r-squared value**. It is defined as follows:\n",
    "\n",
    "* $ \\large SST = \\sum (y_i - \\bar y ) ^2 $\n",
    "\n",
    "* $ \\large SSE = \\sum \\hat{e}_i^2 = \\sum (y_i - \\hat {y}_i ) ^2 $\n",
    "\n",
    "* $ \\large r^2 = 1 - \\frac{SSE}{SST}$\n",
    "\n",
    "Since SST is a constant for the supplied training data, minimizing SSE is equivalent to maximizing $r^2$. The score supplied by $r^2$ has two advantages over SSE:\n",
    "\n",
    "1. The value $r^2$ is \"normalized\" to always be between 0 and 1. A value close to 1 indicates that our model provides a very good fit for the data. \n",
    "2. The $r^2$ value has a useful interpretation not present with SSE. We can think of $r^2$ as reporting the proportion of the variance in the training labels that has been accounted for by our model. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SLR with Scikit-Learn\n",
    "\n",
    "Scikit-Learn is a library that contains implementations of many machine learning algorithms, as well as useful tools for evaluatting models, processing data, and generating synthetic data sets. We will use this package extensively in this class. \n",
    "\n",
    "In this lesson, we will illustrate how to use Scikit-Learn to construct linear regression models. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Intercept:   2.9099999999999984\n",
      "Slope: [2.03]\n",
      "r-Squared is  0.9765165876777251\n"
     ]
    }
   ],
   "source": [
    "#We will now use the `LinearRegression` class from Scikit-Learn to create the SLR model.\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# We create an instance of the LinearRegression() class.\n",
    "# Then we call its fit() method. \n",
    "mod = LinearRegression()\n",
    "mod.fit(X,y)\n",
    "\n",
    "# We print the model parameters. \n",
    "print('Intercept:  ', mod.intercept_)\n",
    "print('Slope:', mod.coef_)\n",
    "\n",
    "# We compute the r_Squared \n",
    "print(\"r-Squared is \", mod.score(X,y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Let's plot   y=b+m*3 with the model parameters we obtain from SKLEARN...\n",
    "plt.close()\n",
    "plt.scatter(x,y)\n",
    "\n",
    "b = mod.intercept_\n",
    "m = mod.coef_[0]\n",
    "plt.plot([0,6],[m*0 + b, m*6 + b], c='r')\n",
    "plt.xlim([0,6])\n",
    "plt.ylim([0,15])\n",
    "plt.xlabel('x')\n",
    "plt.ylabel('y')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5c2f5acba1c34af0916e43084738ca05",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(VBox(children=(FloatSlider(value=2.0, continuous_update=False, layout=Layout(width='200px'), ma…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 550x550 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Playing with a Linear Regression using a Python snippet04.py \n",
    "\n",
    "\n",
    "#With this backend, the output of plotting commands is displayed inline \n",
    "#within frontends like the Jupyter notebook, directly below the code cell that produced it. \n",
    "#The resulting plots will then also be stored in the notebook document.\n",
    "%matplotlib inline\n",
    "%run -i snippets/snippet04.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           x          y\n",
      "0   0.271574   6.386724\n",
      "1   1.658730   8.561736\n",
      "2   2.362137   9.456477\n",
      "3   2.926846   9.695954\n",
      "4   3.430756   9.104633\n",
      "5   4.482566  12.104478\n",
      "6   4.486176  11.420900\n",
      "7   4.740897   9.133291\n",
      "8   5.728787   9.438673\n",
      "9   6.889639  15.383075\n",
      "10  7.772462  13.766021\n",
      "11  8.102013  15.993152\n",
      "(12, 1)\n",
      "(12,)\n"
     ]
    }
   ],
   "source": [
    "### HERE WE GENERATE THE SAME DATA AS IN snippet04.py\n",
    "np.random.seed(163)\n",
    "x = np.random.uniform(low=0, high=10, size=12)\n",
    "x.sort()\n",
    "y = 5 + 1.4 * x + np.random.normal(loc=0, scale=2.5, size=12)\n",
    "print ( pd.DataFrame( {'x':x,  'y':y}))\n",
    "\n",
    "\n",
    "# The features (that is the data in x)  need to be stored in a 2D array or DataFrame\n",
    "# that's why we reshape the one-dimnesional vector x into a 2D array X\n",
    "X = x.reshape(12,1)\n",
    "print(X.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Intercept:   6.209338101745086\n",
      "Slope: [1.058284]\n"
     ]
    }
   ],
   "source": [
    "# We create an instance of the LinearRegression() class.\n",
    "# Then we call its fit() method. \n",
    "mod = LinearRegression()\n",
    "mod.fit(X,y)\n",
    "\n",
    "# We print the model parameters. \n",
    "print('Intercept:  ', mod.intercept_)\n",
    "print('Slope:', mod.coef_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will plot the dataset, along with the line that represents the model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 396x396 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "r-Squared is  0.7758984631440847\n"
     ]
    }
   ],
   "source": [
    "b = mod.intercept_\n",
    "m = mod.coef_[0]\n",
    "\n",
    "plt.close()\n",
    "plt.scatter(x,y)\n",
    "plt.plot([0,10],[m*0 + b, m*10 + b], c='r')\n",
    "plt.xlim([0,10])\n",
    "plt.ylim([0,25])\n",
    "plt.xlabel('x')\n",
    "plt.ylabel('y')\n",
    "plt.show()\n",
    "\n",
    "print(\"r-Squared is \", mod.score(X,y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generating Predictions\n",
    "\n",
    "Ever Scikit-Learn model comes equipped with a `predict` method that can be used to generate predictions. We will use this method to find the `y` values predicted for our model for `x=2`, `x=5`, and `x=8`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3,)\n"
     ]
    }
   ],
   "source": [
    "Xnew = np.array([2, 5, 8])\n",
    "print(Xnew.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The predict function requires a 2D array as input, so we will reshape `Xnew`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 1)\n"
     ]
    }
   ],
   "source": [
    "Xnew = Xnew.reshape((3,1))\n",
    "print(Xnew.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 8.325907 11.500759 14.675612]\n"
     ]
    }
   ],
   "source": [
    "print(mod.predict(Xnew))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Computing SSE and r_Squared using the formulas\n",
    "\n",
    "We know that the parameter values were selected in order to minimize SSE for the given training data. Let's calculate the SSE for the model we have generated. This will require us to use the `predict` method built into our model. \n",
    "\n",
    "\n",
    "* For each training observation $(x_i, y_i)$, let $\\large\\hat{y}_i = b_0 + b_1 x_i$. \n",
    "* For each $i$, calculate the error (residual) $\\large\\hat{e}_i = \\hat{y}_i - y_i$. \n",
    "* The goal of the algorithm is to find the parameter values that minimize the Sum of Squared Errors loss function, given by: $ \\large SSE = \\sum \\hat{e}_i^2 $"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training SSE: 21.02398255445639\n"
     ]
    }
   ],
   "source": [
    "y_hat = mod.predict(X)\n",
    "residuals = y - y_hat\n",
    "\n",
    "SSE = np.sum(residuals**2)\n",
    "\n",
    "print('Training SSE:', SSE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## r-Squared\n",
    "\n",
    "When working with linear regression, the optimal parameter values are determined by minimizing the objective function SSE. However, a different value is typically used to assess the quality of a regression model. This alternate scoring method is called the called the **r-squared value**. It is defined as follows:\n",
    "\n",
    "* $ \\large SST = \\sum (y_i - \\bar y ) ^2 $\n",
    "\n",
    "* $ \\large SSE = \\sum \\hat{e}_i^2 = \\sum (y_i - \\hat {y}_i ) ^2 $\n",
    "\n",
    "* $ \\large r^2 = 1 - \\frac{SSE}{SST}$\n",
    "\n",
    "Since SST is a constant for the supplied training data, minimizing SSE is equivalent to maximizing $r^2$. The score supplied by $r^2$ has two advantages over SSE:\n",
    "\n",
    "1. The value $r^2$ is \"normalized\" to always be between 0 and 1. A value close to 1 indicates that our model provides a very good fit for the data. \n",
    "2. The $r^2$ value has a useful interpretation not present with SSE. We can think of $r^2$ as reporting the proportion of the variance in the training labels that has been accounted for by our model. \n",
    "\n",
    "We will now directly compute the $r^2$ value for our model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7758984631440847\n"
     ]
    }
   ],
   "source": [
    "SST = np.sum((y - np.mean(y))**2)\n",
    "r2 = 1 - SSE / SST\n",
    "print(r2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Scoring the Model directly\n",
    "Scikit-Learn `LinearRegression` objects do not have an `r_squared` attribute, but they do contain a method called `score` that can be used to calcuate $r^2$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7758984631440847\n"
     ]
    }
   ],
   "source": [
    "print(mod.score(X,y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multiple Regression\n",
    "\n",
    "In a multiple linear regression task, we have several features, $X = [x^{(1)}, x^{(2)}, ..., x^{(p)}]$, from which we wish to predict a single continuous, real-valued label `y`.\n",
    "\n",
    "* Assume that our training set has $n$ observations.\n",
    "* Denote the values of the training features for observation number $i$ as $X_i = [x^{(1)}_i, x^{(2)}_i, ..., x^{(p)}_i]$.\n",
    "* Denote the value of the label for observation $i$ as $y_i$. \n",
    "* We assume that our model has the following form: $\\large \\hat{y} = \\hat{\\beta}_0 + \\hat{\\beta}_1 x^{(1)} + \\hat{\\beta}_2 x^{(2)} ... + \\hat{\\beta}_p x^{(p)}$.\n",
    "* In the model above, $\\hat{\\beta}_0$, $\\hat{\\beta}_1$, ..., $\\hat{\\beta}_p$ are model parameters that are learned from the training data. \n",
    "* $\\hat{y}$ represents the predicted value of $y$ given some input vector $X = [x^{(1)}, x^{(2)}, ..., x^{(p)}]$. \n",
    "\n",
    "### Training the Model\n",
    "\n",
    "* Let $b_0, b_1, ..., b_p$ be a set (not necessarily optimal) parameter values used to define a model $\\large \\hat{y} = {b}_0 + {b}_1 x^{(1)} + {b}_2 x^{(2)} + ... + {b}_p x^{(p)}$.\n",
    "* For each training observation $(x_i, y_i)$, let $\\large\\hat{y}_i = {b}_0 + {b}_1 x^{(1)}_i + {b}_2 x^{(2)}_i + ... + {b}_p x^{(p)}_i$.\n",
    "* For each $i$, calculate the error (residual) $\\large\\hat{e}_i = \\hat{y}_i - y_i$. \n",
    "* The goal of the algorithm is to find the parameter values that minimize the Sum of Squared Errors objective function, given by: $ \\large SSE = \\sum \\hat{e}_i^2 $\n",
    "* We will denote the optimal parameter values by $\\hat{\\beta}_0$, $\\hat{\\beta}_1$, ..., $\\hat{\\beta}_p$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example with TWO independent variables \n",
    "\n",
    "We will generate a random dataset to illustrate how multiple regression works. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x1</th>\n",
       "      <th>x2</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4.170220</td>\n",
       "      <td>9.501761</td>\n",
       "      <td>38.139430</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7.203245</td>\n",
       "      <td>5.566532</td>\n",
       "      <td>30.126983</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.001144</td>\n",
       "      <td>9.156063</td>\n",
       "      <td>27.714854</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.023326</td>\n",
       "      <td>6.415662</td>\n",
       "      <td>24.366173</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.467559</td>\n",
       "      <td>3.900077</td>\n",
       "      <td>18.250087</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.923386</td>\n",
       "      <td>4.859907</td>\n",
       "      <td>17.958359</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1.862602</td>\n",
       "      <td>6.043105</td>\n",
       "      <td>25.377172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>3.455607</td>\n",
       "      <td>5.495479</td>\n",
       "      <td>22.752695</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>3.967675</td>\n",
       "      <td>9.261814</td>\n",
       "      <td>37.175761</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>5.388167</td>\n",
       "      <td>9.187334</td>\n",
       "      <td>39.841319</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>4.191945</td>\n",
       "      <td>3.948756</td>\n",
       "      <td>20.203897</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>6.852195</td>\n",
       "      <td>9.632625</td>\n",
       "      <td>43.567475</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          x1        x2          y\n",
       "0   4.170220  9.501761  38.139430\n",
       "1   7.203245  5.566532  30.126983\n",
       "2   0.001144  9.156063  27.714854\n",
       "3   3.023326  6.415662  24.366173\n",
       "4   1.467559  3.900077  18.250087\n",
       "5   0.923386  4.859907  17.958359\n",
       "6   1.862602  6.043105  25.377172\n",
       "7   3.455607  5.495479  22.752695\n",
       "8   3.967675  9.261814  37.175761\n",
       "9   5.388167  9.187334  39.841319\n",
       "10  4.191945  3.948756  20.203897\n",
       "11  6.852195  9.632625  43.567475"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.seed(1)\n",
    "\n",
    "n = 200\n",
    "x1 = np.random.uniform(0, 10, n)\n",
    "x2 = np.random.uniform(0, 10, n)\n",
    "y = 7 + 1.3 * x1 + 2.5 * x2 + np.random.normal(0, 3, n)\n",
    "\n",
    "df = pd.DataFrame({'x1':x1, 'x2':x2, 'y':y})\n",
    "\n",
    "df.head(12)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use the `LinearRegression` class from Scikit-Learn to create multiple regression models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(200, 2)\n",
      "\n",
      "Model intercept: 6.536812277597999\n",
      "\n",
      "Model coefficients: [1.377376 2.506059]\n",
      "\n",
      "r-Squared: 0.8721337623707668\n",
      "the y value for x1=4 and x2=9  is =  [34.600849]\n"
     ]
    }
   ],
   "source": [
    "X = np.hstack([x1.reshape(n,1), x2.reshape(n,1)])\n",
    "\n",
    "print(X.shape)\n",
    "\n",
    "mlr = LinearRegression()\n",
    "mlr.fit(X,y)\n",
    "\n",
    "print('\\nModel intercept:', mlr.intercept_)\n",
    "print('\\nModel coefficients:', mlr.coef_)\n",
    "print('\\nr-Squared:', mlr.score(X,y))\n",
    "\n",
    "Xnew = np.array([4, 9])\n",
    "Xnew = Xnew.reshape((1,2))\n",
    "print(\"the y value for x1=4 and x2=9  is = \", mlr.predict(Xnew))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example: Predicting Median Home Value\n",
    "\n",
    "In this example, we will be working with the \"Boston Housing\" dataset. This dataset contains data for 506 census tracts of Boston from the 1970 census. \n",
    "\n",
    "The dataset contains the following 19 pieces of information for each census tract:\n",
    "* **`town`** - name of town\n",
    "* **`tract`** - census tract\n",
    "* **`lon`** - longitude of census tract\n",
    "* **`lat`** - latitude of census tract \n",
    "* **`medv`** - median value of owner-occupied homes in USD 1000's\n",
    "* **`cmedv`** - corrected median value of owner-occupied homes in USD 1000's\n",
    "* **`crim`** - per capita crime rate by town\n",
    "* **`zn`** - proportion of residential land zoned for lots over 25,000 sq.ft\n",
    "* **`indus`** - proportion of non-retail business acres per town\n",
    "* **`chas`** - Charles River dummy variable (= 1 if tract bounds river; 0 otherwise)\n",
    "* **`nox`** - nitric oxides concentration (parts per 10 million)\n",
    "* **`rm`** - average number of rooms per dwelling\n",
    "* **`age`** - proportion of owner-occupied units built prior to 1940\n",
    "* **`dis`** - weighted distances to five Boston employment centres\n",
    "* **`rad`** - index of accessibility to radial highways\n",
    "* **`tax`** - full-value property-tax rate per USD 10,000\n",
    "* **`ptratio`** - pupil-teacher ratio by town\n",
    "* **`b`** - 1000(B - 0.63)^2 where B is the proportion of blacks by town\n",
    "* **`lstat`** - percentage of lower status of the population\n",
    "\n",
    "We will start by importing the dataset from a text file, and then viewing the first 10 rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>town</th>\n",
       "      <th>tract</th>\n",
       "      <th>lon</th>\n",
       "      <th>lat</th>\n",
       "      <th>medv</th>\n",
       "      <th>cmedv</th>\n",
       "      <th>crim</th>\n",
       "      <th>zn</th>\n",
       "      <th>indus</th>\n",
       "      <th>chas</th>\n",
       "      <th>nox</th>\n",
       "      <th>rm</th>\n",
       "      <th>age</th>\n",
       "      <th>dis</th>\n",
       "      <th>rad</th>\n",
       "      <th>tax</th>\n",
       "      <th>ptratio</th>\n",
       "      <th>b</th>\n",
       "      <th>lstat</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Nahant</td>\n",
       "      <td>2011</td>\n",
       "      <td>-70.955</td>\n",
       "      <td>42.2550</td>\n",
       "      <td>24.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>0.00632</td>\n",
       "      <td>18.0</td>\n",
       "      <td>2.31</td>\n",
       "      <td>0</td>\n",
       "      <td>0.538</td>\n",
       "      <td>6.575</td>\n",
       "      <td>65.2</td>\n",
       "      <td>4.0900</td>\n",
       "      <td>1</td>\n",
       "      <td>296</td>\n",
       "      <td>15.3</td>\n",
       "      <td>396.90</td>\n",
       "      <td>4.98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Swampscott</td>\n",
       "      <td>2021</td>\n",
       "      <td>-70.950</td>\n",
       "      <td>42.2875</td>\n",
       "      <td>21.6</td>\n",
       "      <td>21.6</td>\n",
       "      <td>0.02731</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>6.421</td>\n",
       "      <td>78.9</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2</td>\n",
       "      <td>242</td>\n",
       "      <td>17.8</td>\n",
       "      <td>396.90</td>\n",
       "      <td>9.14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Swampscott</td>\n",
       "      <td>2022</td>\n",
       "      <td>-70.936</td>\n",
       "      <td>42.2830</td>\n",
       "      <td>34.7</td>\n",
       "      <td>34.7</td>\n",
       "      <td>0.02729</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>7.185</td>\n",
       "      <td>61.1</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2</td>\n",
       "      <td>242</td>\n",
       "      <td>17.8</td>\n",
       "      <td>392.83</td>\n",
       "      <td>4.03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Marblehead</td>\n",
       "      <td>2031</td>\n",
       "      <td>-70.928</td>\n",
       "      <td>42.2930</td>\n",
       "      <td>33.4</td>\n",
       "      <td>33.4</td>\n",
       "      <td>0.03237</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>6.998</td>\n",
       "      <td>45.8</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3</td>\n",
       "      <td>222</td>\n",
       "      <td>18.7</td>\n",
       "      <td>394.63</td>\n",
       "      <td>2.94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Marblehead</td>\n",
       "      <td>2032</td>\n",
       "      <td>-70.922</td>\n",
       "      <td>42.2980</td>\n",
       "      <td>36.2</td>\n",
       "      <td>36.2</td>\n",
       "      <td>0.06905</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>7.147</td>\n",
       "      <td>54.2</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3</td>\n",
       "      <td>222</td>\n",
       "      <td>18.7</td>\n",
       "      <td>396.90</td>\n",
       "      <td>5.33</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         town  tract     lon      lat  medv  cmedv     crim    zn  indus  \\\n",
       "0      Nahant   2011 -70.955  42.2550  24.0   24.0  0.00632  18.0   2.31   \n",
       "1  Swampscott   2021 -70.950  42.2875  21.6   21.6  0.02731   0.0   7.07   \n",
       "2  Swampscott   2022 -70.936  42.2830  34.7   34.7  0.02729   0.0   7.07   \n",
       "3  Marblehead   2031 -70.928  42.2930  33.4   33.4  0.03237   0.0   2.18   \n",
       "4  Marblehead   2032 -70.922  42.2980  36.2   36.2  0.06905   0.0   2.18   \n",
       "\n",
       "   chas    nox     rm   age     dis  rad  tax  ptratio       b  lstat  \n",
       "0     0  0.538  6.575  65.2  4.0900    1  296     15.3  396.90   4.98  \n",
       "1     0  0.469  6.421  78.9  4.9671    2  242     17.8  396.90   9.14  \n",
       "2     0  0.469  7.185  61.1  4.9671    2  242     17.8  392.83   4.03  \n",
       "3     0  0.458  6.998  45.8  6.0622    3  222     18.7  394.63   2.94  \n",
       "4     0  0.458  7.147  54.2  6.0622    3  222     18.7  396.90   5.33  "
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('data/BostonHousingV2.txt', sep='\\t')\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check the dimensions of the DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(506, 19)\n",
      "         town  tract     lon      lat  medv  cmedv     crim    zn  indus  \\\n",
      "0      Nahant   2011 -70.955  42.2550  24.0   24.0  0.00632  18.0   2.31   \n",
      "1  Swampscott   2021 -70.950  42.2875  21.6   21.6  0.02731   0.0   7.07   \n",
      "2  Swampscott   2022 -70.936  42.2830  34.7   34.7  0.02729   0.0   7.07   \n",
      "3  Marblehead   2031 -70.928  42.2930  33.4   33.4  0.03237   0.0   2.18   \n",
      "4  Marblehead   2032 -70.922  42.2980  36.2   36.2  0.06905   0.0   2.18   \n",
      "\n",
      "   chas    nox     rm   age     dis  rad  tax  ptratio       b  lstat  \n",
      "0     0  0.538  6.575  65.2  4.0900    1  296     15.3  396.90   4.98  \n",
      "1     0  0.469  6.421  78.9  4.9671    2  242     17.8  396.90   9.14  \n",
      "2     0  0.469  7.185  61.1  4.9671    2  242     17.8  392.83   4.03  \n",
      "3     0  0.458  6.998  45.8  6.0622    3  222     18.7  394.63   2.94  \n",
      "4     0  0.458  7.147  54.2  6.0622    3  222     18.7  396.90   5.33  \n"
     ]
    }
   ],
   "source": [
    "print(df.shape)\n",
    "print(df.head(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use this dataset for a regression task in which we will attempt to predict the label `cmedv` using the last 13 columns as features. We will now prepare our feature and label arrays. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(506, 13)\n",
      "(506,)\n"
     ]
    }
   ],
   "source": [
    "X = df.iloc[:,6:].values\n",
    "y = df.iloc[:,5].values\n",
    "\n",
    "print(X.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to measure how well our model generalizes to new data, we will create a train/test split of our data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(404, 13)\n",
      "(102, 13)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1)\n",
    "\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will now use the `LinearRegression` class to create our model. We will use the `score` method of our trained model to calculate the r-Squared value on our training set, as well as on our test set. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training r-Squared: 0.7341832055169144\n",
      "Testing r-Squared:  0.763957915736643\n"
     ]
    }
   ],
   "source": [
    "model = LinearRegression()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "print(\"Training r-Squared:\", model.score(X_train, y_train))\n",
    "print(\"Testing r-Squared: \", model.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model object has attributes containing the optimal parameter values that define our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42.76113154507837\n",
      "[ -0.110315   0.06       0.021576   2.134697 -19.522247   3.075544\n",
      "   0.004304  -1.536018   0.303108  -0.011639  -0.950799   0.0072\n",
      "  -0.551868]\n"
     ]
    }
   ],
   "source": [
    "np.set_printoptions(precision=6, suppress=True)\n",
    "\n",
    "print(model.intercept_)\n",
    "print(model.coef_)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using a Subset of the Available Features\n",
    "\n",
    "It is often undesireable to use all features that are potentially available to you in a supervised learning task. A few reasons why you might want to consider using a subset of the available features are:\n",
    "\n",
    "* Using too many features could result in over-fitting. \n",
    "* Some features might not be relevant.\n",
    "* Some features might be redundant. \n",
    "* Having too many features can have a negative impact on the interpretability of your model. \n",
    "* It might be expensive or time-consuming to collect values for certain features. \n",
    "\n",
    "Let train a second MLR model on this data, but this time using only the features `rm`, `ptratio`, and `lstat`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rm</th>\n",
       "      <th>ptratio</th>\n",
       "      <th>lstat</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6.575</td>\n",
       "      <td>15.3</td>\n",
       "      <td>4.98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6.421</td>\n",
       "      <td>17.8</td>\n",
       "      <td>9.14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7.185</td>\n",
       "      <td>17.8</td>\n",
       "      <td>4.03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6.998</td>\n",
       "      <td>18.7</td>\n",
       "      <td>2.94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7.147</td>\n",
       "      <td>18.7</td>\n",
       "      <td>5.33</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      rm  ptratio  lstat\n",
       "0  6.575     15.3   4.98\n",
       "1  6.421     17.8   9.14\n",
       "2  7.185     17.8   4.03\n",
       "3  6.998     18.7   2.94\n",
       "4  7.147     18.7   5.33"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.iloc[:, [11,16,18]].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(506, 3)\n"
     ]
    }
   ],
   "source": [
    "Xs = df.iloc[:,[11,16,18]].values\n",
    "\n",
    "print(Xs.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xs_train, Xs_test, y_train, y_test = train_test_split(Xs, y, test_size=0.2, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training r-Squared: 0.6739085856095928\n",
      "Testing r-Squared:  0.6958714532115466\n"
     ]
    }
   ],
   "source": [
    "model_s = LinearRegression()\n",
    "model_s.fit(Xs_train, y_train)\n",
    "\n",
    "print(\"Training r-Squared:\", model_s.score(Xs_train, y_train))\n",
    "print(\"Testing r-Squared: \", model_s.score(Xs_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that both r-Squared values are LOWER than those computed previously (when we used the last 13 columns).  Since the Testing r-squared value given above is LOWER than the Testing r-squared value with 13 columns - we will keep the former model..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23.927244156450747\n",
      "[ 3.795969 -0.952999 -0.597414]\n"
     ]
    }
   ],
   "source": [
    "print(model_s.intercept_)\n",
    "print(model_s.coef_)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
