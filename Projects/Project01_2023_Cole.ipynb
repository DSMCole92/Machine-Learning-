{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Project 01_2023\n",
    "\n",
    "**Lance Cole**\n",
    "\n",
    "**DSCI 35600 - Machine Learning**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part A: Import Packages and Load Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the cell below, import the following packages using the standard aliases: `numpy`, `matplotlib.pyplot`, and `pandas`. Also import the following classes and functions from `sklearn`: `train_test_split`,  `LinearRegression`, `PolynomialFeatures`,  `LogisticRegression`, `StandardScaler`, and `OneHotEncoder`.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use `pandas` to load the contents of the tab-separated file `Project01_data.txt` into a dataframe called `df`. Display the first 10 rows of this dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>F1</th>\n",
       "      <th>F2</th>\n",
       "      <th>F3</th>\n",
       "      <th>F4</th>\n",
       "      <th>F5</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>15.69</td>\n",
       "      <td>-0.771</td>\n",
       "      <td>550.880459</td>\n",
       "      <td>P</td>\n",
       "      <td>D</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-16.81</td>\n",
       "      <td>1.959</td>\n",
       "      <td>588.523801</td>\n",
       "      <td>Q</td>\n",
       "      <td>C</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>21.09</td>\n",
       "      <td>-1.550</td>\n",
       "      <td>660.881834</td>\n",
       "      <td>P</td>\n",
       "      <td>B</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>15.64</td>\n",
       "      <td>-1.623</td>\n",
       "      <td>374.414543</td>\n",
       "      <td>Q</td>\n",
       "      <td>C</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>14.25</td>\n",
       "      <td>1.426</td>\n",
       "      <td>446.714120</td>\n",
       "      <td>Q</td>\n",
       "      <td>B</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>21.54</td>\n",
       "      <td>1.231</td>\n",
       "      <td>525.126448</td>\n",
       "      <td>P</td>\n",
       "      <td>D</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>-14.05</td>\n",
       "      <td>1.608</td>\n",
       "      <td>343.264320</td>\n",
       "      <td>P</td>\n",
       "      <td>B</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>-21.52</td>\n",
       "      <td>-1.858</td>\n",
       "      <td>549.753447</td>\n",
       "      <td>Q</td>\n",
       "      <td>B</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>12.31</td>\n",
       "      <td>-0.941</td>\n",
       "      <td>507.148376</td>\n",
       "      <td>Q</td>\n",
       "      <td>D</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>-24.83</td>\n",
       "      <td>-1.940</td>\n",
       "      <td>627.040100</td>\n",
       "      <td>Q</td>\n",
       "      <td>B</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      F1     F2          F3 F4 F5  y\n",
       "0  15.69 -0.771  550.880459  P  D  0\n",
       "1 -16.81  1.959  588.523801  Q  C  3\n",
       "2  21.09 -1.550  660.881834  P  B  2\n",
       "3  15.64 -1.623  374.414543  Q  C  0\n",
       "4  14.25  1.426  446.714120  Q  B  0\n",
       "5  21.54  1.231  525.126448  P  D  2\n",
       "6 -14.05  1.608  343.264320  P  B  3\n",
       "7 -21.52 -1.858  549.753447  Q  B  1\n",
       "8  12.31 -0.941  507.148376  Q  D  0\n",
       "9 -24.83 -1.940  627.040100  Q  B  1"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('Project01_data.txt', sep='\\t')\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Your goal in this assignment will be to use features F1 - F5 to predict one of four possible values for y: 0, 1, 2, or 3. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part B: Preparing the Data\n",
    "\n",
    "Using Lecture6, in the cell below, create the following arrays:\n",
    "\n",
    "* `X_num` should contain the columns of `df` associated with numerical variables. \n",
    "* `X_cat` should contain the columns of `df` associated with categorical variables. \n",
    "* `y` should be a 1D array contain the values of the label, `y`. \n",
    "\n",
    "Print first 3 rows of each of these three arrays."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(467, 3)\n",
      "(467, 2)\n",
      "(467,)\n"
     ]
    }
   ],
   "source": [
    "X_num = df.iloc[:,:3].values\n",
    "X_cat = df.iloc[:,[3,4]].values\n",
    "y = df.iloc[:,-1]\n",
    "\n",
    "print(X_num.shape)\n",
    "print(X_cat.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Numerical Features\n",
    "Split `Xnum` into training and validation sets called `X_num_train` and `X_num_val`. Use an 80/20 split, and set `random_state=1`. \n",
    "\n",
    "Then use the `StandardScaler` class to scale the numerical data. Name the resulting arrays `X_sca_train` and `X_sca_val`. Print the shape of these two arrays. \n",
    "Print the top 5 rows of `X_sca_train`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(373, 3)\n",
      "(94, 3)\n",
      "X_sca_train = \n",
      "[[-1.34790978 -0.85473365 -0.03279194]\n",
      " [-0.70984609 -0.4799912   0.9331761 ]\n",
      " [-0.98459949  1.88147176  2.06401676]\n",
      " ...\n",
      " [ 0.95173081 -0.89923432 -0.40795084]\n",
      " [ 0.7468011   0.98560309 -0.96206722]\n",
      " [-0.15636557  1.0558673  -0.28997942]]\n"
     ]
    }
   ],
   "source": [
    "X_num_train, X_num_val, y_num_train, y_num_val = train_test_split(X_num, y, test_size=0.2, random_state=1)\n",
    "s_scaler = StandardScaler()\n",
    "\n",
    "X_sca_train = s_scaler.fit_transform(X_num_train)\n",
    "X_sca_val = s_scaler.fit_transform(X_num_val)\n",
    "\n",
    "print(X_sca_train.shape)\n",
    "print(X_sca_val.shape)\n",
    "\n",
    "print(\"X_sca_train = \")\n",
    "print(X_sca_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Categorical Features\n",
    "\n",
    "Use the `OneHotEncoder` class to encode the categorical feature array (setting `sparse=False`). Store the results in an array called `X_enc`. \n",
    "\n",
    "Split `X_enc` into training and validation sets called `X_enc_train` and `X_enc_val`. Use an 80/20 split, and set `random_state=1`. Print the shapes of these two arrays."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(373, 6)\n",
      "(94, 6)\n"
     ]
    }
   ],
   "source": [
    "enc = OneHotEncoder(sparse=False)\n",
    "X_enc = enc.fit_transform(X_cat)\n",
    "\n",
    "X_enc_train, X_enc_val, y_enc_train, y_enc_val = train_test_split(X_enc, y, test_size=0.2, random_state=1)\n",
    "\n",
    "print(X_enc_train.shape)\n",
    "print(X_enc_val.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Combine Numerical and Categorial Features\n",
    "\n",
    "Use `np.hstack()` to combine `X_sca_train` and `X_enc_train` into an array called `X_train`. Then combine `X_sca_val` and `X_enc_val` into an array called `X_val`. Print the shapes of the two new arrays."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(94, 9)\n",
      "(373, 9)\n"
     ]
    }
   ],
   "source": [
    "X_train = np.hstack([X_sca_train, X_enc_train])\n",
    "X_val = np.hstack([X_sca_val, X_enc_val])\n",
    "print(X_val.shape)\n",
    "print(X_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part C: Polynomial Regression Model\n",
    "\n",
    "Using lecture 8, in the cell below create and fit polynomial models with degrees 1,3,4,5,7.  Fit the models and compute the training and validation scores for each.  Do not plot anything.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- Degree 1 --\n",
      "Training r2:   0.6382751443295913\n",
      "Validation r2: 0.5334020784605253 \n",
      "\n",
      "-- Degree 3 --\n",
      "Training r2:   0.8228042419821453\n",
      "Validation r2: 0.8224250413792191 \n",
      "\n",
      "-- Degree 5 --\n",
      "Training r2:   0.8508252764216662\n",
      "Validation r2: 0.8788413864576491 \n",
      "\n",
      "-- Degree 7 --\n",
      "Training r2:   0.8728242410836947\n",
      "Validation r2: 0.12019555086909062 \n",
      "\n",
      "-- Degree 9 --\n",
      "Training r2:   0.8899490344773456\n",
      "Validation r2: -0.10629843366074265 \n",
      "\n",
      "-- Degree 11 --\n",
      "Training r2:   0.9108177814282042\n",
      "Validation r2: -101.55739174294352 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "degree = [1, 3, 5, 7, 9, 11]\n",
    "x_curve = np.linspace(-4, 4, 100)\n",
    "tr_score = []\n",
    "va_score = []\n",
    "\n",
    "np.random.seed(1)\n",
    "n = 40\n",
    "x = np.random.uniform(-4, 4, n)\n",
    "X = x.reshape(-1,1)\n",
    "y =  0.3 + 0.05 * x + 0.001 * x**7 + np.random.normal(0, 2, n)\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.4, random_state=1)\n",
    "\n",
    "for i in range(len(degree)):\n",
    "    \n",
    "    poly = PolynomialFeatures(degree[i])\n",
    "    Xp_train = poly.fit_transform(X_train)\n",
    "    Xp_val = poly.fit_transform(X_val)\n",
    "    \n",
    "    mod = LinearRegression()\n",
    "    mod.fit(Xp_train, y_train)\n",
    "    \n",
    "    tr_score.append(mod.score(Xp_train, y_train))\n",
    "    va_score.append(mod.score(Xp_val, y_val))\n",
    "\n",
    "    xp_curve = poly.fit_transform(x_curve.reshape(-1,1))\n",
    "    y_curve = mod.predict(xp_curve)\n",
    "    \n",
    "    print('-- Degree', degree[i], '--')\n",
    "    print('Training r2:  ', tr_score[i])\n",
    "    print('Validation r2:', va_score[i], '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use the best model to predict some values \n",
    "Pick the model with the best validation score and use it to predict the y-values from the top 5 rows of Xp_val.   Print out both the predicted values and the actual values from y_val.  Don't forget to round off the predicted y-values using np.round()."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## more predictions...\n",
    "Finally predict the y values for the following set of data:\n",
    "\n",
    "`F1      F2      F3     F4  F5`\n",
    "\n",
    "`10.6  -0.9 \t650.9   Q   D `\n",
    "\n",
    "Don't forget the you have to prepare the data like you did in part B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
